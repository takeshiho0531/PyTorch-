{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featureモジュールの解説と実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#パッケージのインポート\n",
    "import glob\n",
    "import os.path as osp\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import models,transforms\n",
    "import cv2 \n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FeatureMap_convolutionの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DBatchNormRelu(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,stride,padding,dilation,bias):\n",
    "        super(conv2DBatchNormRelu,self).__init__()\n",
    "        self.conv=nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,dilation,bias=bias)\n",
    "        self.batchnorm=nn.BatchNorm2d(out_channels)\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "        #inplace設定で、入力を保存せずに出力を計算し、メモリ削減する\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.conv(x)\n",
    "        x=self.batchnorm(x)\n",
    "        outputs=self.relu(x)\n",
    "\n",
    "        return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureMap_convolution(nn.Module):\n",
    "    def __init__(self):\n",
    "        \"\"\" 構成するネットワークを用意 \"\"\"\n",
    "        super(FeatureMap_convolution,self).__init__()\n",
    "\n",
    "        #畳み込み層1\n",
    "        in_channels,out_channels,kernel_size,stride,padding,dilation,bias = 3,64,3,2,1,1,False\n",
    "        self.cbnr_1=conv2DBatchNormRelu(in_channels,out_channels,kernel_size,stride,padding,dilation,bias)\n",
    "\n",
    "        #畳み込み層2\n",
    "        in_channels,out_channels,kernel_size,stride,padding,dilation,bias=64,64,3,1,1,1,False\n",
    "        self.cbnr_2=conv2DBatchNormRelu(in_channels,out_channels,kernel_size,stride,padding,dilation,bias)\n",
    "\n",
    "        #畳み込み層3\n",
    "        in_channels,out_channels,kernel_size,stride,padding,dilation,bias=64,128,3,1,1,1,False\n",
    "        self.cbnr_3=conv2DBatchNormRelu(in_channels,out_channels,kernel_size,stride,padding,dilation,bias)\n",
    "\n",
    "        #MaxPooling層\n",
    "        self.maxpool=nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x=self.cbnr_1(x)\n",
    "        x=self.cbnr_2(x)\n",
    "        x=self.cbnr_3(x)\n",
    "        outputs=self.maxpool(x)\n",
    "        return outputs\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResidualBlockPSP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlockPSP(nn.Sequential):\n",
    "    def __init__(self,n_blocks,in_channels,mid_channels,out_channels,stride,dilation):\n",
    "        super(ResidualBlockPSP,self).__init__()\n",
    "\n",
    "        #bottleNeckPSPの用意\n",
    "        self.add_module(\n",
    "            \"block1\",\n",
    "            bottleNeckPSP(in_channels,mid_channels,out_channels,stride,dilation)\n",
    "        )\n",
    "\n",
    "        #bottleNeckIdentifyPSPの繰り返しの用意\n",
    "        for i in range(n_blocks-1):\n",
    "            self.add_module(\n",
    "                \"block\"+str(i+2),\n",
    "                bottleNeckIdentifyPSP(out_channels,mid_channels,stride,dilation)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv2DBatchNorm(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size,stride,padding,dilation,bias):\n",
    "        super(conv2DBatchNorm,self).__init__()\n",
    "        self.conv=nn.Conv2d(in_channels,out_channels,kernel_size,stride,padding,dilation,bias=bias)\n",
    "        self.batchnorm=nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=self.conv(x)\n",
    "        outputs=self.batchnorm(x)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleNeckPSP(nn.Module):\n",
    "    def __init__(self,in_channels,mid_channels,out_channels,stride,dilation):\n",
    "        super(bottleNeckPSP,self).__init__()\n",
    "\n",
    "        self.cbr_1=conv2DBatchNormRelu(in_channels,mid_channels,kernel_size=1,stride=1,padding=0,\n",
    "                                 dilation=1,bias=False)\n",
    "        self.cbr_2=conv2DBatchNormRelu(mid_channels,mid_channels,kernel_size=3,stride=stride,padding=dilation,\n",
    "                                 dilation=dilation,bias=False)\n",
    "        self.cbr_3=conv2DBatchNorm(mid_channels,out_channels,kernel_size=1,stride=1,padding=0,\n",
    "                                 dilation=1,bias=False)\n",
    "\n",
    "        #スキップ結合\n",
    "        self.cb_residual=conv2DBatchNorm(in_channels,out_channels,kernel_size=1,stride=stride,padding=0,\n",
    "                                 dilation=1,bias=False)\n",
    "\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self,x):\n",
    "        conv=self.cbr_3(self.cbr_2(self.cbr_1))\n",
    "        residual=self.cb_residual(x)\n",
    "        return self.relu(conv+residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bottleNeckIdentifyPSP(nn.Module):\n",
    "    def __init__(self,in_channels,mid_channels,out_channels,stride,dilation):\n",
    "        super(bottleNeckIdentifyPSP,self).__init__()\n",
    "\n",
    "        self.cbr_1=conv2DBatchNormRelu(in_channels,mid_channels,kernel_size=1,stride=1,padding=0,\n",
    "                                 dilation=1,bias=False)\n",
    "        self.cbr_2=conv2DBatchNormRelu(mid_channels,mid_channels,kernel_size=3,stride=1,padding=dilation,\n",
    "                                 dilation=dilation,bias=False)\n",
    "        self.cbr_3=conv2DBatchNorm(mid_channels,out_channels,kernel_size=1,stride=1,padding=0,\n",
    "                                 dilation=1,bias=False)\n",
    "        self.relu=nn.ReLU(inplace=True)\n",
    "\n",
    "        \n",
    "    def forward(self,x):\n",
    "        conv=self.cbr_3(self.cbr_2(self.cbr_1))\n",
    "        residual=x\n",
    "        return self.relu(conv+residual)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('pytorchenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8eafc1c3d0ba1f317c23d0e9aa4360a9d8a5b5ceacbb507f9d0793fa2c9bc9e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
