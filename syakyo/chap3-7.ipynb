{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ファインチューニングによる学習と検証の実施"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#パッケージのインポート\n",
    "import glob\n",
    "import os.path as osp\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import models,transforms\n",
    "import cv2 \n",
    "import time\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習・検証の実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataloader import make_datapath_list,DataTransform,VOCDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ファイルパスリストの作成\n",
    "rootpath=\"../3_semantic_segmentation/data/VOCdevkit/VOC2012/\"\n",
    "\n",
    "train_img_list,train_anno_list,val_img_list,val_anno_list =make_datapath_list(rootpath=rootpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datasetの作成\n",
    "\n",
    "#(RGB)の色の平均値と標準偏差\n",
    "color_mean=(0.485,0.456,0.406)\n",
    "color_std=(0.229,0.224,0.225)\n",
    "\n",
    "train_dataset=VOCDataset(train_img_list,train_anno_list,phase=\"train\",transform=DataTransform(\n",
    "    input_size=475,color_mean=color_mean,color_std=color_std))\n",
    "\n",
    "val_dataset=VOCDataset(val_img_list,val_anno_list,phase=\"val\",transform=DataTransform(\n",
    "    input_size=475,color_mean=color_mean,color_std=color_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataLoaderの作成\n",
    "batch_size=8\n",
    "\n",
    "train_dataloader=data.DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "val_dataloader=data.DataLoader(val_dataset,batch_size=batch_size,shuffle=False)\n",
    "\n",
    "#辞書型変数にまとめる\n",
    "dataloaders_dict={\"train\":train_dataloader, \"val\":val_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ネットワークモデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pspnet import PSPNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ネットワーク設定完了：学習済みの重みをロードしました。\n"
     ]
    }
   ],
   "source": [
    "#ファインチューニングでPSPNetを作成\n",
    "#ADE20Kデータセットの学習済みモデルを使用、ADE20Kはクラス数が150です\n",
    "net=PSPNet(n_classes=150)\n",
    "\n",
    "#ADE20Kの学習済みパラメータをロード\n",
    "state_dict=torch.load(\"../3_semantic_segmentation/weights/pspnet50_ADE20K.pth\")\n",
    "net.load_state_dict(state_dict)\n",
    "\n",
    "#分類用の畳み込み層を、出力層21のものに付け替える\n",
    "n_classes=21\n",
    "net.decode_feature.classification=nn.Conv2d(\n",
    "    in_channels=512,out_channels=n_classes,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "net.aux.classification=nn.Conv2d(\n",
    "    in_channels=256,out_channels=n_classes,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "#付け替えた畳み込み層を初期化する\n",
    "#活性化関数がシグモイド関数なのでXavierを使用する\n",
    "def weights_init(m):\n",
    "    if isinstance(m,nn.Conv2d):\n",
    "        nn.init.xavier_normal_(m.weight.data)\n",
    "        if m.bias is not None: #バイアス項がある場合\n",
    "            nn.init.constant_(m.bias,0.0)\n",
    "\n",
    "\n",
    "net.decode_feature.classification.apply(weights_init)\n",
    "net.aux.classification.apply(weights_init)\n",
    "\n",
    "print(\"ネットワーク設定完了：学習済みの重みをロードしました。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 損失関数の設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PSPLoss(nn.Module):\n",
    "    \"\"\" PSPNetの損失関数のクラスです \"\"\"\n",
    "\n",
    "    def __init__(self,aux_weight=0.4):\n",
    "        super(PSPLoss,self).__init__()\n",
    "        self.aux_weight=aux_weight #aux_lossの重み\n",
    "\n",
    "    def forward(self,outputs,targets):\n",
    "        \"\"\" \n",
    "        損失関数の計算。 \n",
    "\n",
    "        Parameters\n",
    "        ---------------\n",
    "        outputs : PSPNetの出力(tuple)\n",
    "              (output=torch.Size([num_batch,21,475,475]),output_aux=torch.Size([num_batch,21,475,475]))\n",
    "        targets : [num_batch,475,475]\n",
    "              正解のアノテーション情報\n",
    "\n",
    "\n",
    "        Returns\n",
    "        ---------------\n",
    "        loss : テンソル\n",
    "               損失の値\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        loss=F.cross_entropy(outputs[0],targets,reduction=\"mean\")\n",
    "        loss_aux=F.cross_entropy(outputs[1],targets,reduction=\"mean\")\n",
    "\n",
    "        return loss+self.aux_weight*loss_aux\n",
    "\n",
    "criterion=PSPLoss(aux_weight=0.4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## スケジューラーを利用したepochごとの学習率の変更"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ファインチューニングなので、学習率は小さく\n",
    "optimizer=optim.SGD([\n",
    "    {\"params\":net.feature_conv.parameters(),\"lr\":1e-3},\n",
    "    {\"params\":net.feature_res_1.parameters(),\"lr\":1e-3},\n",
    "    {\"params\":net.feature_res_2.parameters(),\"lr\":1e-3},\n",
    "    {\"params\":net.feature_dilated_res_1.parameters(),\"lr\":1e-3},\n",
    "    {\"params\":net.feature_dilated_res_2.parameters(),\"lr\":1e-3},\n",
    "    {\"params\":net.pyramid_pooling.parameters(),\"lr\":1e-3},\n",
    "    {\"params\":net.decode_feature.parameters(),\"lr\":1e-2},\n",
    "    {\"params\":net.aux.parameters(),\"lr\":1e-2},],\n",
    "    momentum=0.9,weight_decay=0.0001)\n",
    "\n",
    "#スケジューラーの設定\n",
    "def lambda_epoch(epoch):\n",
    "    max_epoch=30\n",
    "    return math.pow((1-epoch/max_epoch),0.9)\n",
    "\n",
    "sceduler=optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習・検証"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#モデルを学習させる関数を設定\n",
    "def train_model(net,dataloaders_dict,criterion,scheduler,optimizer,num_epochs):\n",
    "\n",
    "    #GPUが使えるかを確認\n",
    "    device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用デバイス：\", device)\n",
    "\n",
    "    #ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    #ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark=True\n",
    "\n",
    "    #画像の枚数\n",
    "    num_train_imgs=len(dataloaders_dict[\"train\"].dataset)\n",
    "    num_val_imgs=len(dataloaders_dict[\"val\"].dataset)\n",
    "    batch_size=dataloaders_dict[\"train\"].batch_size\n",
    "\n",
    "    #イテレーションカウンタをセット\n",
    "    iteration=1\n",
    "    logs=[]\n",
    "\n",
    "    #multiple minibatch\n",
    "    batch_multiplier=3\n",
    "\n",
    "    #epochのループ\n",
    "    for epoch in range(num_epochs):\n",
    "        #開始時刻を保存\n",
    "        t_epoch_start=time.time()\n",
    "        t_iter_start=time.time()\n",
    "        epoch_train_loss=0.0 #epochの損失和\n",
    "        epoch_val_loss=0.0 #epochの損失和\n",
    "\n",
    "        print(\"----------\")\n",
    "        print(\"Epoch {}/{}\".format(epoch+1,num_epochs))\n",
    "        print(\"----------\")\n",
    "\n",
    "        #epochごとの訓練と検証のループ\n",
    "        for phase in [\"train\",\"val\"]:\n",
    "            if phase==\"train\":\n",
    "                net.train() #モデルを訓練モードに\n",
    "                scheduler.step() #最適化のschduler更新\n",
    "                optimizer.zero_grad()\n",
    "                print(\"(train\")\n",
    "\n",
    "            else:\n",
    "                if ((epoch+1)%5==0):\n",
    "                    net.eval() #モデルを検証モードに\n",
    "                    print(\"----------\")\n",
    "                    print(\"(val)\")\n",
    "                else:\n",
    "                    #検証は5回に1回だけ行う\n",
    "                    continue\n",
    "\n",
    "            #データローダーからminibatchずつ取り出すループ\n",
    "            count=0\n",
    "            for imges,anno_class_imges in dataloaders_dict[phase]:\n",
    "\n",
    "                #GPUが使えるならGPUにデータを送る\n",
    "                imges=imges.to(device)\n",
    "                anno_class_imges=anno_class_imges.to(device)\n",
    "\n",
    "                #multiple minibatchでのパラメータの更新\n",
    "                if (phase==\"train\") and (count==0):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "                    count=batch_multiplier\n",
    "\n",
    "                #順伝搬(forward)計算\n",
    "                with torch.set_grad_enabled(phase==\"train\"):\n",
    "                    outputs=net(imges)\n",
    "                    loss=criterion(outputs,anno_class_imges.long())/batch_multiplier\n",
    "\n",
    "                    #訓練時はバックプロパゲーション\n",
    "                    if phase==\"train\":\n",
    "                        loss.backward() #勾配の計算\n",
    "                        count-=1 #multiple minibatch\n",
    "\n",
    "                        if (iteration%10==0): #10iterに1度lossを表示\n",
    "                            t_iter_finish=time.time()\n",
    "                            duration=t_iter_finish-t_iter_start\n",
    "                            print(\"イテレーション{}||Loss:{:.4f} || 10iter:{:.4f} sec.\".format(\n",
    "                                iteration,\n",
    "                                loss.item()/batch_size*batch_multiplier, duration))\n",
    "                            t_iter_start=0\n",
    "\n",
    "                    #検証時\n",
    "                    else:\n",
    "                        epoch_val_loss+=loss.item()*batch_multiplier\n",
    "\n",
    "\n",
    "        #epochのphaseごとのlossと正解率\n",
    "        t_epoch_finish=time.time()\n",
    "        print(\"----------\")\n",
    "        print(\"epoch{}||Epoch_TRAIN_Loss:{:.4f}||Epoch_VAL_Loss:{:.4f}\".format(\n",
    "            epoch+1, epoch_train_loss/num_train_imgs, epoch_val_loss/num_val_imgs))\n",
    "\n",
    "        print(\"timer: {:.4f} sec.\".format(t_epoch_finish-t_epoch_start))\n",
    "        t_epoch_start=0\n",
    "\n",
    "        #ログを保存\n",
    "        log_epoch={\"epoch\":epoch+1, \"train_loss\":epoch_train_loss/num_train_imgs, \n",
    "        \"val_loss\":epoch_val_loss/num_val_imgs}\n",
    "\n",
    "        logs.append(log_epoch)\n",
    "        df=pd.DataFrame(logs)\n",
    "        df.to_csv(\"log_output_chap3.csv\")\n",
    "\n",
    "    #最後のネットワークを保存する\n",
    "    torch.save(net.state_dict(),\"weights/pspnet50_\"+str(epoch+1)+\".pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#学習・検証を実行する\n",
    "num_epochs=30\n",
    "train_model(net,dataloaders_dict,criterion,scheduler,optimizer,num_epochs=num_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 ('pytorchenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8eafc1c3d0ba1f317c23d0e9aa4360a9d8a5b5ceacbb507f9d0793fa2c9bc9e9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
